{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec98fa80b1704edbb2000a6d72b8c281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1bddb52445614c6d89720a97accfb715",
              "IPY_MODEL_19d411e27f0c4b4ba1a145f27f20d5c4",
              "IPY_MODEL_7fc44d9cb5b94253aee4d7084f4e0276"
            ],
            "layout": "IPY_MODEL_542e060791074cbd8dcad3c1aaf4aa36"
          }
        },
        "1bddb52445614c6d89720a97accfb715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_540e85ef1688454780a39dc655d1ac8e",
            "placeholder": "​",
            "style": "IPY_MODEL_2b3e7f2d168e43588ea818dd139f0ffb",
            "value": ""
          }
        },
        "19d411e27f0c4b4ba1a145f27f20d5c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e519f59a14940a5baec362c4293497f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4571928dc084fcc8888dc306308b54c",
            "value": 0
          }
        },
        "7fc44d9cb5b94253aee4d7084f4e0276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb7e559a15f848dc877c2bfa9b72b6e6",
            "placeholder": "​",
            "style": "IPY_MODEL_fd6ea106cafb4b178b43a281e8f15ed6",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "542e060791074cbd8dcad3c1aaf4aa36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "540e85ef1688454780a39dc655d1ac8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b3e7f2d168e43588ea818dd139f0ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e519f59a14940a5baec362c4293497f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e4571928dc084fcc8888dc306308b54c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb7e559a15f848dc877c2bfa9b72b6e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd6ea106cafb4b178b43a281e8f15ed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df4cb170d1d14342a3d31f9a4ea62c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0578dde26b2947babe28742dda0df596",
              "IPY_MODEL_985ce6bac21046988d16827531d856b0",
              "IPY_MODEL_92d0af16e27447959042ca50e0381dee"
            ],
            "layout": "IPY_MODEL_21fbfeddb7d2413eb351638ae9b2ea24"
          }
        },
        "0578dde26b2947babe28742dda0df596": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90b36fc2efc343cbb2c3c7dbd5db1b40",
            "placeholder": "​",
            "style": "IPY_MODEL_d65f6092f3d648ada85a979273bc2826",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "985ce6bac21046988d16827531d856b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef6ba7e853a9400dacfc9f7b046113a2",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b5b4d84654c419890f11d808f9811d2",
            "value": 2
          }
        },
        "92d0af16e27447959042ca50e0381dee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c2b0ce1b92146b59d0465e01339066a",
            "placeholder": "​",
            "style": "IPY_MODEL_6badb3ac42864edeb6d9ec316031efb3",
            "value": " 2/2 [00:40&lt;00:00, 19.03s/it]"
          }
        },
        "21fbfeddb7d2413eb351638ae9b2ea24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90b36fc2efc343cbb2c3c7dbd5db1b40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d65f6092f3d648ada85a979273bc2826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef6ba7e853a9400dacfc9f7b046113a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b5b4d84654c419890f11d808f9811d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c2b0ce1b92146b59d0465e01339066a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6badb3ac42864edeb6d9ec316031efb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYlCC_Qf-5yK",
        "outputId": "32765e0c-e8ce-43b0-cad5-88e4f480bc23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "HUGGINGFACE_TOKEN=\"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\"\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(token=HUGGINGFACE_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers==4.43.0 accelerate\n",
        "\n",
        "# Download Microsoft's Phi-3-mini-4k-instruct model\n",
        "!huggingface-cli download microsoft/Phi-3-mini-4k-instruct --local-dir /content/Phi-3-mini-4k-instruct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afrdmRjl-8FZ",
        "outputId": "f52fbafc-515b-4678-c584-ebf78c5bb838"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.43.0\n",
            "  Downloading transformers-4.43.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.0) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.0) (0.31.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.0) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.0) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.0) (2.32.3)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers==4.43.0)\n",
            "  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.0) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.43.0) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.43.0) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.43.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.43.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.43.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.43.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.43.0) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading transformers-4.43.0-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, transformers\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.1\n",
            "    Uninstalling tokenizers-0.21.1:\n",
            "      Successfully uninstalled tokenizers-0.21.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.52.2\n",
            "    Uninstalling transformers-4.52.2:\n",
            "      Successfully uninstalled transformers-4.52.2\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tokenizers-0.19.1 transformers-4.43.0\n",
            "Fetching 19 files:   0% 0/19 [00:00<?, ?it/s]Downloading '.gitattributes' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.dab9a4e17afd2ef39d90ccb0b40ef2786fe77422.incomplete'\n",
            "Downloading 'LICENSE' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/DhCjcNQuMpl4FL346qr3tvNUCgY=.700edcc5f42c4816520bc554926ad7e0d9e613d7.incomplete'\n",
            "Downloading 'CODE_OF_CONDUCT.md' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/K98JAqu7X0Q8Wy3TIHRTrEErCiw=.c72a5749c52ac97bca71c672ef5295d303d22b05.incomplete'\n",
            "Downloading 'config.json' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/8_PA_wEVGiVa2goH2H4KQOQpvVY=.b9b031fadda61a035b2e8ceb4362cbf604002b21.incomplete'\n",
            "Downloading 'NOTICE.md' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/1kHSXNens9SagnzeekbYfJkxzXM=.56ff7dcadd87eb0bec57dbba00f005b6622c2809.incomplete'\n",
            "Downloading 'SECURITY.md' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/hSrnLtSfgijFBTW07bq7w-it8Jg=.6b906d43bc2057e6a832c3236897b2e514d6e1e7.incomplete'\n",
            "Downloading 'added_tokens.json' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/SeqzFlf9ZNZ3or_wZAOIdsM3Yxw=.178968dec606c790aa335e9142f6afec37288470.incomplete'\n",
            "\n",
            "LICENSE: 100% 1.10k/1.10k [00:00<00:00, 6.26MB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/LICENSE\n",
            "\n",
            ".gitattributes: 100% 1.55k/1.55k [00:00<00:00, 12.6MB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/.gitattributes\n",
            "Fetching 19 files:   5% 1/19 [00:00<00:03,  5.86it/s]\n",
            "CODE_OF_CONDUCT.md: 100% 453/453 [00:00<00:00, 2.91MB/s]\n",
            "Downloading 'README.md' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.b2124325c54aacd33e08d872d96d25d4eeede0ab.incomplete'\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/CODE_OF_CONDUCT.md\n",
            "\n",
            "config.json: 100% 967/967 [00:00<00:00, 7.70MB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/config.json\n",
            "\n",
            "NOTICE.md: 100% 1.81k/1.81k [00:00<00:00, 15.2MB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/NOTICE.md\n",
            "\n",
            "SECURITY.md: 100% 2.70k/2.70k [00:00<00:00, 22.8MB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/SECURITY.md\n",
            "\n",
            "added_tokens.json: 100% 306/306 [00:00<00:00, 1.63MB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/added_tokens.json\n",
            "Downloading 'configuration_phi3.py' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/vEnnZuZbPjs88GEHAS5wEyJ0R4s=.780401034b66c92c6ce76ffc541493b6eac61627.incomplete'\n",
            "Downloading 'generation_config.json' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/3EVKVggOldJcKSsGjSdoUCN1AyQ=.1cae169b9d7155e10038aa446691d296a44e01dc.incomplete'\n",
            "\n",
            "README.md: 100% 21.6k/21.6k [00:00<00:00, 75.7MB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/README.md\n",
            "Downloading 'model-00001-of-00002.safetensors' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/aoe4E07IMh7reFyUkVoVk040mQk=.b7492726c01287bf6e13c3d74c65ade3d436d50da1cf5bb6925bc962419d6610.incomplete'\n",
            "Downloading 'model-00002-of-00002.safetensors' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/Dr_lZJDwE1cnGAQMwA77jJEQIk8=.3f311787aa136e858556caa8543015161edcad85ba81b6a36072443d7fa73c87.incomplete'\n",
            "Downloading 'modeling_phi3.py' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/LlzfabVCMqA3OEpgzTLO_-uTIq4=.c2742b929803c3d483a67c09f9487a6848b3fb27.incomplete'\n",
            "Downloading 'model.safetensors.index.json' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/yVzAsSxRSINSz-tQbpx-TLpfkLU=.3aa7bba5cb52d7ea1e71bf8540f70e35e3cf24f7.incomplete'\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "configuration_phi3.py: 100% 11.2k/11.2k [00:00<00:00, 40.9MB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/configuration_phi3.py\n",
            "Fetching 19 files:  47% 9/19 [00:00<00:00, 31.61it/s]Downloading 'sample_finetune.py' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/jAxnWmhUwJLetDEtQVplPQs35Fk=.66b6e2e6adf0131e0ae8507826085df1aca4b5bd.incomplete'\n",
            "\n",
            "\n",
            "generation_config.json: 100% 181/181 [00:00<00:00, 896kB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/generation_config.json\n",
            "Downloading 'special_tokens_map.json' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/ahkChHUJFxEmOdq5GDFEmerRzCY=.c6a944b4d49ce5d79030250ed6bdcbb1a65dfda1.incomplete'\n",
            "\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 0.00/2.67G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "modeling_phi3.py:   0% 0.00/73.2k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors.index.json: 100% 16.5k/16.5k [00:00<00:00, 70.4MB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/model.safetensors.index.json\n",
            "modeling_phi3.py: 100% 73.2k/73.2k [00:00<00:00, 7.05MB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/modeling_phi3.py\n",
            "\n",
            "\n",
            "\n",
            "sample_finetune.py: 100% 6.40k/6.40k [00:00<00:00, 30.2MB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/sample_finetune.py\n",
            "Downloading 'tokenizer.json' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/HgM_lKo9sdSCfRtVg7MMFS7EKqo=.88ec145f4e7684c009bc6d55df24bb82c7d3c379.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "special_tokens_map.json: 100% 599/599 [00:00<00:00, 2.60MB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/special_tokens_map.json\n",
            "Downloading 'tokenizer.model' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/7iVfz3cUOMr-hyjiqqRDHEwVBAM=.9e556afd44213b6bd1be2b850ebbbd98f5481437a8021afaf58ee7fb1818d347.incomplete'\n",
            "Downloading 'tokenizer_config.json' to '/content/Phi-3-mini-4k-instruct/.cache/huggingface/download/vzaExXFZNBay89bvlQv-ZcI6BTg=.67aa82cddb4d66391ddf31ff99f059239bd2d1e7.incomplete'\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.model:   0% 0.00/500k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   0% 10.5M/2.67G [00:00<00:38, 68.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json:   0% 0.00/1.94M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 5.97MB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/tokenizer.model\n",
            "\n",
            "\n",
            "\n",
            "tokenizer_config.json: 100% 3.44k/3.44k [00:00<00:00, 15.8MB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/tokenizer_config.json\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/4.97G [00:00<00:54, 91.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   1% 21.0M/2.67G [00:00<00:37, 70.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.json: 100% 1.94M/1.94M [00:00<00:00, 10.6MB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/tokenizer.json\n",
            "\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/4.97G [00:00<00:40, 121MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   2% 41.9M/2.67G [00:00<00:24, 109MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 73.4M/4.97G [00:00<00:39, 125MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   2% 62.9M/2.67G [00:00<00:23, 111MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 94.4M/4.97G [00:00<00:36, 132MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   3% 83.9M/2.67G [00:00<00:20, 129MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 115M/4.97G [00:00<00:37, 130MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   4% 105M/2.67G [00:00<00:19, 129MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   5% 126M/2.67G [00:01<00:18, 139MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 136M/4.97G [00:01<00:36, 134MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 157M/4.97G [00:01<00:35, 137MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   5% 147M/2.67G [00:01<00:19, 131MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 178M/4.97G [00:01<00:33, 142MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   6% 168M/2.67G [00:01<00:18, 138MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 199M/4.97G [00:01<00:34, 139MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   7% 189M/2.67G [00:01<00:17, 140MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 220M/4.97G [00:01<00:33, 143MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   8% 210M/2.67G [00:01<00:19, 127MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 241M/4.97G [00:01<00:36, 130MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   9% 231M/2.67G [00:01<00:20, 120MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 262M/4.97G [00:02<00:40, 117MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:   9% 252M/2.67G [00:02<00:21, 110MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 283M/4.97G [00:02<00:46, 101MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  10% 273M/2.67G [00:05<02:02, 19.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  11% 283M/2.67G [00:06<02:12, 18.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 304M/4.97G [00:06<04:42, 16.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  11% 304M/2.67G [00:06<01:32, 25.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 325M/4.97G [00:06<03:26, 22.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  12% 325M/2.67G [00:06<01:10, 33.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 346M/4.97G [00:06<02:36, 29.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 357M/4.97G [00:06<02:17, 33.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  13% 336M/2.67G [00:06<01:01, 37.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  13% 357M/2.67G [00:06<00:45, 50.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 377M/4.97G [00:06<01:43, 44.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  14% 377M/2.67G [00:06<00:36, 63.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 398M/4.97G [00:06<01:20, 56.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 419M/4.97G [00:07<01:05, 69.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  15% 398M/2.67G [00:06<00:29, 76.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 440M/4.97G [00:07<00:55, 81.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  16% 419M/2.67G [00:07<00:25, 86.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 461M/4.97G [00:07<00:50, 89.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  16% 440M/2.67G [00:07<00:23, 94.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  17% 461M/2.67G [00:07<00:20, 107MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 482M/4.97G [00:07<00:44, 101MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 503M/4.97G [00:07<00:43, 103MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  18% 482M/2.67G [00:07<00:20, 106MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 524M/4.97G [00:07<00:40, 110MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  19% 503M/2.67G [00:07<00:19, 112MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 545M/4.97G [00:08<00:41, 107MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  20% 524M/2.67G [00:08<00:19, 108MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 566M/4.97G [00:08<00:40, 109MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  20% 545M/2.67G [00:08<00:19, 110MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 587M/4.97G [00:08<00:37, 116MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  21% 566M/2.67G [00:08<00:18, 114MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 608M/4.97G [00:08<00:36, 120MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  22% 587M/2.67G [00:08<00:17, 117MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 629M/4.97G [00:08<00:33, 129MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  23% 608M/2.67G [00:08<00:17, 120MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 650M/4.97G [00:08<00:34, 127MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  24% 629M/2.67G [00:08<00:16, 124MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 671M/4.97G [00:09<00:34, 125MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  24% 650M/2.67G [00:09<00:16, 121MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 692M/4.97G [00:09<00:34, 124MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  25% 671M/2.67G [00:09<00:16, 121MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 713M/4.97G [00:09<00:34, 122MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  26% 692M/2.67G [00:09<00:16, 117MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 734M/4.97G [00:09<00:37, 113MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  27% 713M/2.67G [00:09<00:17, 112MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 755M/4.97G [00:09<00:38, 110MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  27% 734M/2.67G [00:09<00:17, 113MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 776M/4.97G [00:09<00:37, 113MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  28% 755M/2.67G [00:09<00:15, 122MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  29% 776M/2.67G [00:10<00:14, 131MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 797M/4.97G [00:10<00:34, 121MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  30% 797M/2.67G [00:10<00:14, 127MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 818M/4.97G [00:10<00:36, 115MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  31% 818M/2.67G [00:10<00:14, 132MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 839M/4.97G [00:10<00:35, 116MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  31% 839M/2.67G [00:10<00:13, 139MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 860M/4.97G [00:10<00:33, 122MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  32% 860M/2.67G [00:10<00:12, 142MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  33% 881M/2.67G [00:10<00:12, 148MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  34% 912M/2.67G [00:10<00:10, 171MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 881M/4.97G [00:11<00:44, 92.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 902M/4.97G [00:11<00:36, 110MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  35% 933M/2.67G [00:11<00:10, 163MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  36% 954M/2.67G [00:11<00:11, 156MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 923M/4.97G [00:11<00:36, 110MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  37% 975M/2.67G [00:11<00:11, 152MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 944M/4.97G [00:11<00:34, 116MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  37% 996M/2.67G [00:11<00:11, 149MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 965M/4.97G [00:11<00:33, 121MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  38% 1.02G/2.67G [00:11<00:10, 151MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 986M/4.97G [00:11<00:30, 133MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  39% 1.04G/2.67G [00:11<00:11, 148MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.01G/4.97G [00:11<00:27, 145MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.03G/4.97G [00:12<00:27, 143MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  40% 1.06G/2.67G [00:11<00:11, 141MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  40% 1.08G/2.67G [00:12<00:11, 143MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 1.05G/4.97G [00:12<00:28, 138MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  41% 1.10G/2.67G [00:12<00:13, 116MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.07G/4.97G [00:12<00:35, 111MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  42% 1.12G/2.67G [00:12<00:12, 125MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.09G/4.97G [00:12<00:31, 125MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  43% 1.14G/2.67G [00:12<00:11, 137MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 1.11G/4.97G [00:12<00:28, 135MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  44% 1.16G/2.67G [00:12<00:10, 143MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.13G/4.97G [00:12<00:26, 143MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  44% 1.18G/2.67G [00:12<00:10, 139MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 1.15G/4.97G [00:13<00:30, 127MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  45% 1.21G/2.67G [00:13<00:14, 101MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.17G/4.97G [00:13<00:37, 100MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.20G/4.97G [00:13<00:34, 109MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  46% 1.23G/2.67G [00:13<00:14, 102MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 1.22G/4.97G [00:13<00:30, 122MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  47% 1.25G/2.67G [00:13<00:12, 112MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.24G/4.97G [00:13<00:31, 120MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  48% 1.27G/2.67G [00:13<00:11, 118MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.26G/4.97G [00:14<00:48, 76.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  48% 1.29G/2.67G [00:14<00:18, 74.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  49% 1.31G/2.67G [00:14<00:15, 88.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.28G/4.97G [00:14<00:42, 87.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.30G/4.97G [00:14<00:35, 104MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  50% 1.33G/2.67G [00:14<00:13, 102MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.32G/4.97G [00:14<00:30, 121MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  51% 1.35G/2.67G [00:14<00:11, 119MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.34G/4.97G [00:14<00:26, 135MB/s]\u001b[A\n",
            "\n",
            "Fetching 19 files:  47% 9/19 [00:20<00:00, 31.61it/s]\n",
            "model-00001-of-00002.safetensors:  27% 1.36G/4.97G [00:20<05:05, 11.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.39G/4.97G [00:20<03:09, 18.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.42G/4.97G [00:20<02:21, 25.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  52% 1.39G/2.67G [00:20<01:52, 11.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  53% 1.42G/2.67G [00:20<01:19, 15.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.44G/4.97G [00:20<01:53, 31.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  54% 1.44G/2.67G [00:20<00:57, 21.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.46G/4.97G [00:21<01:30, 39.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  55% 1.46G/2.67G [00:21<00:42, 28.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.48G/4.97G [00:21<01:10, 49.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  55% 1.48G/2.67G [00:21<00:31, 38.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.50G/4.97G [00:21<00:55, 62.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  56% 1.50G/2.67G [00:21<00:23, 49.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.52G/4.97G [00:21<00:45, 75.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  57% 1.52G/2.67G [00:21<00:18, 61.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.55G/4.97G [00:21<00:35, 96.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  58% 1.54G/2.67G [00:21<00:15, 72.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.57G/4.97G [00:26<03:59, 14.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  59% 1.56G/2.67G [00:26<01:27, 12.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.60G/4.97G [00:26<02:35, 21.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  60% 1.59G/2.67G [00:26<00:53, 20.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  60% 1.61G/2.67G [00:26<00:40, 26.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.63G/4.97G [00:26<02:00, 27.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  61% 1.64G/2.67G [00:26<00:30, 34.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.65G/4.97G [00:26<01:33, 35.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  62% 1.66G/2.67G [00:26<00:22, 44.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.67G/4.97G [00:27<01:12, 45.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  63% 1.69G/2.67G [00:27<00:15, 62.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.70G/4.97G [00:27<00:51, 63.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  64% 1.71G/2.67G [00:27<00:13, 69.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.72G/4.97G [00:27<00:46, 70.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  65% 1.73G/2.67G [00:27<00:12, 76.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.74G/4.97G [00:27<00:42, 75.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  66% 1.75G/2.67G [00:31<01:02, 14.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.76G/4.97G [00:32<04:05, 13.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  66% 1.76G/2.67G [00:32<01:01, 14.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  67% 1.78G/2.67G [00:32<00:42, 21.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.79G/4.97G [00:32<02:37, 20.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  68% 1.80G/2.67G [00:32<00:29, 29.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.81G/4.97G [00:32<02:01, 26.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  68% 1.82G/2.67G [00:33<00:22, 37.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.84G/4.97G [00:33<01:35, 32.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  69% 1.85G/2.67G [00:33<00:16, 48.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.86G/4.97G [00:33<01:13, 42.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  70% 1.87G/2.67G [00:33<00:13, 59.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/4.97G [00:33<00:58, 52.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.90G/4.97G [00:33<00:47, 65.0MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  71% 1.89G/2.67G [00:33<00:10, 71.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  71% 1.91G/2.67G [00:33<00:09, 83.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.92G/4.97G [00:33<00:41, 73.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  72% 1.93G/2.67G [00:33<00:07, 94.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.94G/4.97G [00:33<00:36, 83.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  73% 1.95G/2.67G [00:33<00:06, 107MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.96G/4.97G [00:34<00:31, 96.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.98G/4.97G [00:34<00:26, 114MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  74% 1.97G/2.67G [00:34<00:06, 113MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 2.00G/4.97G [00:34<00:25, 114MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  75% 1.99G/2.67G [00:34<00:06, 111MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.02G/4.97G [00:34<00:25, 114MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  75% 2.01G/2.67G [00:34<00:06, 105MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 2.04G/4.97G [00:35<00:40, 72.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  76% 2.03G/2.67G [00:38<00:44, 14.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.07G/4.97G [00:39<03:12, 15.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  77% 2.06G/2.67G [00:39<00:30, 19.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 2.10G/4.97G [00:39<02:00, 23.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  78% 2.08G/2.67G [00:39<00:21, 27.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.12G/4.97G [00:39<01:31, 31.3MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  79% 2.10G/2.67G [00:39<00:15, 36.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.14G/4.97G [00:39<01:10, 40.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  79% 2.12G/2.67G [00:39<00:11, 46.7MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 2.16G/4.97G [00:39<00:54, 51.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  80% 2.14G/2.67G [00:39<00:08, 60.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.19G/4.97G [00:39<00:39, 69.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  81% 2.16G/2.67G [00:39<00:07, 71.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 2.21G/4.97G [00:39<00:35, 77.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  82% 2.18G/2.67G [00:39<00:06, 78.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.23G/4.97G [00:40<00:37, 72.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  82% 2.20G/2.67G [00:44<00:37, 12.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 2.25G/4.97G [00:44<03:19, 13.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  84% 2.23G/2.67G [00:45<00:21, 20.0MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.29G/4.97G [00:45<02:06, 21.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  84% 2.25G/2.67G [00:45<00:15, 26.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 2.31G/4.97G [00:45<01:35, 27.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  85% 2.28G/2.67G [00:45<00:11, 34.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.33G/4.97G [00:45<01:14, 35.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  86% 2.30G/2.67G [00:45<00:08, 44.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 2.35G/4.97G [00:45<00:57, 45.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.37G/4.97G [00:45<00:44, 58.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  87% 2.33G/2.67G [00:45<00:05, 61.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 2.39G/4.97G [00:45<00:43, 59.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  88% 2.35G/2.67G [00:46<00:05, 56.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  89% 2.37G/2.67G [00:49<00:15, 19.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  90% 2.40G/2.67G [00:49<00:09, 28.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.41G/4.97G [00:49<02:31, 16.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  91% 2.43G/2.67G [00:49<00:05, 41.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 2.44G/4.97G [00:49<01:35, 26.4MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  92% 2.45G/2.67G [00:49<00:04, 46.5MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.46G/4.97G [00:49<01:19, 31.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  93% 2.47G/2.67G [00:49<00:03, 49.3MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.49G/4.97G [00:50<01:07, 36.7MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  93% 2.50G/2.67G [00:50<00:02, 60.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.51G/4.97G [00:50<00:52, 47.1MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  94% 2.52G/2.67G [00:50<00:02, 73.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.54G/4.97G [00:50<00:36, 67.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  95% 2.55G/2.67G [00:50<00:01, 95.2MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.57G/4.97G [00:50<00:29, 82.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  96% 2.57G/2.67G [00:50<00:01, 86.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.59G/4.97G [00:50<00:29, 80.9MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  97% 2.59G/2.67G [00:50<00:00, 87.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.61G/4.97G [00:51<00:26, 87.6MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  98% 2.61G/2.67G [00:51<00:00, 102MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.63G/4.97G [00:51<00:22, 103MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors:  99% 2.64G/2.67G [00:51<00:00, 119MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.66G/4.97G [00:51<00:19, 119MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors: 100% 2.66G/2.67G [00:51<00:00, 117MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 2.67G/2.67G [00:51<00:00, 51.7MB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/model-00002-of-00002.safetensors\n",
            "\n",
            "model-00001-of-00002.safetensors:  54% 2.71G/4.97G [00:51<00:19, 117MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.74G/4.97G [00:51<00:15, 144MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.76G/4.97G [00:51<00:15, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.78G/4.97G [00:52<00:20, 108MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.80G/4.97G [00:52<00:28, 77.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.81G/4.97G [00:55<01:45, 20.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.85G/4.97G [00:55<00:56, 37.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.89G/4.97G [00:55<00:35, 59.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.93G/4.97G [00:55<00:26, 77.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.96G/4.97G [00:55<00:22, 91.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.98G/4.97G [00:55<00:19, 103MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.01G/4.97G [00:55<00:15, 129MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 3.04G/4.97G [00:56<00:12, 153MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.07G/4.97G [00:56<00:10, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 3.10G/4.97G [00:56<00:09, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 3.14G/4.97G [00:56<00:08, 206MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.17G/4.97G [00:56<00:08, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 3.20G/4.97G [00:56<00:08, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 3.23G/4.97G [00:56<00:08, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.26G/4.97G [00:57<00:07, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 3.29G/4.97G [00:57<00:07, 239MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.32G/4.97G [00:57<00:07, 232MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 3.36G/4.97G [00:57<00:07, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 3.39G/4.97G [00:57<00:07, 216MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.42G/4.97G [00:57<00:07, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 3.45G/4.97G [00:57<00:07, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 3.48G/4.97G [00:58<00:06, 224MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.51G/4.97G [00:58<00:06, 226MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 3.54G/4.97G [00:58<00:06, 210MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.58G/4.97G [00:58<00:06, 205MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 3.60G/4.97G [00:58<00:06, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.62G/4.97G [00:58<00:06, 200MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 3.64G/4.97G [00:58<00:07, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.67G/4.97G [00:59<00:06, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 3.69G/4.97G [00:59<00:07, 167MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.71G/4.97G [00:59<00:07, 166MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.73G/4.97G [00:59<00:07, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.75G/4.97G [00:59<00:07, 167MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.77G/4.97G [01:03<01:11, 16.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.81G/4.97G [01:03<00:44, 26.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.84G/4.97G [01:03<00:29, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.88G/4.97G [01:03<00:18, 59.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.91G/4.97G [01:04<00:13, 75.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.94G/4.97G [01:04<00:10, 97.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.97G/4.97G [01:04<00:08, 122MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.02G/4.97G [01:04<00:06, 158MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 4.05G/4.97G [01:04<00:05, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 4.09G/4.97G [01:04<00:04, 204MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 4.12G/4.97G [01:04<00:04, 211MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.15G/4.97G [01:04<00:03, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 4.18G/4.97G [01:05<00:03, 221MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.22G/4.97G [01:05<00:03, 217MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 4.25G/4.97G [01:05<00:03, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 4.29G/4.97G [01:05<00:02, 257MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 4.32G/4.97G [01:05<00:02, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.35G/4.97G [01:05<00:02, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 4.38G/4.97G [01:05<00:02, 241MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.41G/4.97G [01:06<00:02, 256MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 4.45G/4.97G [01:06<00:01, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 4.49G/4.97G [01:06<00:01, 286MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 4.52G/4.97G [01:06<00:01, 258MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.55G/4.97G [01:06<00:01, 223MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 4.58G/4.97G [01:06<00:01, 203MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.61G/4.97G [01:07<00:02, 140MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 4.63G/4.97G [01:09<00:10, 33.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 4.68G/4.97G [01:09<00:05, 50.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 4.72G/4.97G [01:09<00:03, 72.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.75G/4.97G [01:09<00:02, 91.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 4.78G/4.97G [01:10<00:01, 112MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 4.81G/4.97G [01:10<00:01, 136MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.85G/4.97G [01:10<00:00, 171MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 4.89G/4.97G [01:10<00:00, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 4.92G/4.97G [01:10<00:00, 213MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 4.97G/4.97G [01:10<00:00, 70.3MB/s]\n",
            "Download complete. Moving file to /content/Phi-3-mini-4k-instruct/model-00001-of-00002.safetensors\n",
            "Fetching 19 files: 100% 19/19 [01:11<00:00,  3.74s/it]\n",
            "/content/Phi-3-mini-4k-instruct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Define model path\n",
        "model_id = \"/content/Phi-3-mini-4k-instruct\"\n",
        "\n",
        "# Fix config.json to handle any potential issues (e.g., rope_scaling)\n",
        "config_path = os.path.join(model_id, \"config.json\")\n",
        "if os.path.exists(config_path):\n",
        "    with open(config_path, \"r\") as f:\n",
        "        config = json.load(f)\n",
        "    # Ensure rope_scaling is properly formatted or removed\n",
        "    if \"rope_scaling\" in config and config[\"rope_scaling\"] is not None:\n",
        "        if \"type\" not in config[\"rope_scaling\"]:\n",
        "            config[\"rope_scaling\"][\"type\"] = \"linear\"  # Default to linear scaling\n",
        "        config[\"rope_scaling\"][\"factor\"] = config[\"rope_scaling\"].get(\"factor\", 1.0)\n",
        "    else:\n",
        "        config[\"rope_scaling\"] = None  # Disable rope_scaling if not needed\n",
        "    with open(config_path, \"w\") as f:\n",
        "        json.dump(config, f, indent=2)\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# Set pad_token_id to eos_token_id if not already set\n",
        "if tokenizer.pad_token_id is None:\n",
        "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
        "\n",
        "# Load the Phi model, ensuring it's on CUDA\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"cuda\",  # Explicitly place model on GPU\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16  # Optimize for T4 GPU\n",
        ").to(\"cuda\")  # Ensure model is moved to GPU\n",
        "\n",
        "# Prepare input with attention mask\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a pirate chatbot who always responds in pirate speak!\"},\n",
        "    {\"role\": \"user\", \"content\": \"Who are you?\"}\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\")\n",
        "input_ids = inputs.to(\"cuda\")\n",
        "attention_mask = input_ids.ne(tokenizer.pad_token_id).to(\"cuda\")  # Create attention mask\n",
        "\n",
        "# Generate output with keyword arguments and sampling enabled\n",
        "outputs = model.generate(\n",
        "    input_ids=input_ids,\n",
        "    attention_mask=attention_mask,\n",
        "    max_new_tokens=256,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        "    do_sample=True  # Enable sampling for temperature and top_p\n",
        ")\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "ec98fa80b1704edbb2000a6d72b8c281",
            "1bddb52445614c6d89720a97accfb715",
            "19d411e27f0c4b4ba1a145f27f20d5c4",
            "7fc44d9cb5b94253aee4d7084f4e0276",
            "542e060791074cbd8dcad3c1aaf4aa36",
            "540e85ef1688454780a39dc655d1ac8e",
            "2b3e7f2d168e43588ea818dd139f0ffb",
            "9e519f59a14940a5baec362c4293497f",
            "e4571928dc084fcc8888dc306308b54c",
            "fb7e559a15f848dc877c2bfa9b72b6e6",
            "fd6ea106cafb4b178b43a281e8f15ed6",
            "df4cb170d1d14342a3d31f9a4ea62c23",
            "0578dde26b2947babe28742dda0df596",
            "985ce6bac21046988d16827531d856b0",
            "92d0af16e27447959042ca50e0381dee",
            "21fbfeddb7d2413eb351638ae9b2ea24",
            "90b36fc2efc343cbb2c3c7dbd5db1b40",
            "d65f6092f3d648ada85a979273bc2826",
            "ef6ba7e853a9400dacfc9f7b046113a2",
            "2b5b4d84654c419890f11d808f9811d2",
            "7c2b0ce1b92146b59d0465e01339066a",
            "6badb3ac42864edeb6d9ec316031efb3"
          ]
        },
        "id": "IGC4fo9u_Qwb",
        "outputId": "5a5ccad3-c134-4a97-c3a5-1fc0e078c1b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec98fa80b1704edbb2000a6d72b8c281"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.Phi-3-mini-4k-instruct.modeling_phi3:`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
            "WARNING:transformers_modules.Phi-3-mini-4k-instruct.modeling_phi3:Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df4cb170d1d14342a3d31f9a4ea62c23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
            "WARNING:transformers_modules.Phi-3-mini-4k-instruct.modeling_phi3:You are not running the flash-attention implementation, expect numerical differences.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a pirate chatbot who always responds in pirate speak! Who are you? Yarrr, me hearties! I be a digital buccaneer, here to assist ye in yer quest for knowledge and information. I be a pirate chatbot, ready to parley with ye in the tongue of the sea dogs!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def remove_first_number_group(text):\n",
        "    # Match either:\n",
        "    # 1. A group of 2–5 space-separated digit blocks\n",
        "    # 2. OR a single long number (8+ digits)\n",
        "    match = re.search(r'((\\d+\\s+){1,4}\\d+|\\d{8,})', text)\n",
        "    if match:\n",
        "        return text[:match.start()].rstrip() + ' ' + text[match.end():].lstrip()\n",
        "    return text\n",
        "\n",
        "file_path = '/content/drive/MyDrive/preprocessed_cv_text_data.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "df['Combined_Text'] = df['Category'] + \" \" + df['Processed_Text']\n",
        "df['Combined_Text'] = df['Combined_Text'].str.replace('-', ' ', regex=True)\n",
        "df['Combined_Text'] = df['Combined_Text'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
        "df['Combined_Text'] = df['Combined_Text'].apply(remove_first_number_group)\n",
        "df.head()\n",
        "\n",
        "def chunk_text(text, max_length=1000, overlap=200):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = start + max_length\n",
        "        chunks.append(text[start:end])\n",
        "        start += max_length - overlap\n",
        "    return chunks\n",
        "\n",
        "all_chunks = []\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    chunks = chunk_text(row['Combined_Text'])\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        all_chunks.append({\n",
        "            'cv_id': idx,\n",
        "            'chunk_id': i,\n",
        "            'text': chunk\n",
        "        })\n",
        "\n",
        "# Create DataFrame containing chunks\n",
        "chunk_df = pd.DataFrame(all_chunks)\n",
        "chunk_df.head()\n",
        "\n",
        "chunk_df.to_csv('/content/drive/MyDrive/chunk_cv_text_data.csv')"
      ],
      "metadata": {
        "id": "jE9DK4_A_TkS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5liuL7bMA9hm",
        "outputId": "cb989728-1bc0-47b9-8f0f-926f093ce185"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Category                                               Text  \\\n",
              "0      -net-developer  Contact [email protected] +61 412 345 678 Skil...   \n",
              "1      -net-developer  Contact [email protected] +55 (11) 98765-4321 ...   \n",
              "2      -net-developer  Contact [email protected] +39 02 1234 5678 Ski...   \n",
              "3  -net-web-developer  Contact [email protected] +55 11 91234-5678 Sk...   \n",
              "4  -net-web-developer  Contact [email protected] +81 90-1234-5678 Ski...   \n",
              "\n",
              "                                      Processed_Text  \\\n",
              "0  61 412 345 678 skill c net framework aspnet sq...   \n",
              "1  55 11 987654321 skill c net framework aspnet c...   \n",
              "2  39 02 1234 5678 skill c net framework aspnet s...   \n",
              "3  55 11 912345678 skill aspnet c mvc agile metho...   \n",
              "4  81 9012345678 skill c net aspnet mvc sql serve...   \n",
              "\n",
              "                                       Combined_Text  \n",
              "0  net developer skill c net framework aspnet sql...  \n",
              "1  net developer skill c net framework aspnet cor...  \n",
              "2  net developer skill c net framework aspnet sql...  \n",
              "3  net web developer skill aspnet c mvc agile met...  \n",
              "4  net web developer skill c net aspnet mvc sql s...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85fa17e0-52c3-4ba9-b992-f0056f98f610\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Text</th>\n",
              "      <th>Processed_Text</th>\n",
              "      <th>Combined_Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-net-developer</td>\n",
              "      <td>Contact [email protected] +61 412 345 678 Skil...</td>\n",
              "      <td>61 412 345 678 skill c net framework aspnet sq...</td>\n",
              "      <td>net developer skill c net framework aspnet sql...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-net-developer</td>\n",
              "      <td>Contact [email protected] +55 (11) 98765-4321 ...</td>\n",
              "      <td>55 11 987654321 skill c net framework aspnet c...</td>\n",
              "      <td>net developer skill c net framework aspnet cor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-net-developer</td>\n",
              "      <td>Contact [email protected] +39 02 1234 5678 Ski...</td>\n",
              "      <td>39 02 1234 5678 skill c net framework aspnet s...</td>\n",
              "      <td>net developer skill c net framework aspnet sql...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-net-web-developer</td>\n",
              "      <td>Contact [email protected] +55 11 91234-5678 Sk...</td>\n",
              "      <td>55 11 912345678 skill aspnet c mvc agile metho...</td>\n",
              "      <td>net web developer skill aspnet c mvc agile met...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-net-web-developer</td>\n",
              "      <td>Contact [email protected] +81 90-1234-5678 Ski...</td>\n",
              "      <td>81 9012345678 skill c net aspnet mvc sql serve...</td>\n",
              "      <td>net web developer skill c net aspnet mvc sql s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85fa17e0-52c3-4ba9-b992-f0056f98f610')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-85fa17e0-52c3-4ba9-b992-f0056f98f610 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-85fa17e0-52c3-4ba9-b992-f0056f98f610');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-baff00ef-f03d-452c-8a48-dcb373fb3642\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-baff00ef-f03d-452c-8a48-dcb373fb3642')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-baff00ef-f03d-452c-8a48-dcb373fb3642 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8221,\n  \"fields\": [\n    {\n      \"column\": \"Category\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4162,\n        \"samples\": [\n          \"java-team-lead\",\n          \"marine-engineer\",\n          \"agricultural-worker\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8221,\n        \"samples\": [\n          \"Contact [email\\u00a0protected] +1 (555) 987-6543 Skills \\u2022 Team Leadership \\u2022 Cleaning Protocols \\u2022 Inventory Management \\u2022 Safety Compliance \\u2022 Training & Development Michael Thompson Toronto, Ontario | himalayas.app/@michaelthompson Dedicated Custodial Supervisor with over 6 years of experience in facility management and cleaning operations. Proven track record in leading teams to maintain cleanliness and safety standards in diverse environments, while optimizing cleaning procedures for efficiency and cost-effectiveness. Professional Experience CleanSweep Services Toronto, Ontario Custodial Supervisor Mar 2021 - Present Supervised a team of 15 custodial staff, ensuring adherence to safety protocols and high cleaning standards. Implemented a new cleaning schedule that improved operational efficiency by 30%. Conducted regular training sessions on equipment usage and chemical safety, reducing workplace accidents by 50%. SparkleClean Inc. Toronto, Ontario Lead Custodian Jan 2018 - Feb 2021 Managed daily cleaning operations for a 200,000 sq ft facility, ensuring compliance with health and safety regulations. Developed and maintained inventory tracking system for cleaning supplies, reducing costs by 15%. Collaborated with management to ensure customer satisfaction and resolve any cleaning-related issues promptly. MetroClean Solutions Toronto, Ontario Custodian May 2016 - Dec 2017 Maintained cleanliness in offices and common areas, adhering to company standards and schedules. Assisted in training new staff on cleaning procedures and safety guidelines. Recognized for exceptional service by receiving employee of the month award twice. Education George Brown College Toronto, Ontario Diploma in Facility Management 2014 - 2016 Focus on operations management, health and safety regulations, and cleaning technologies.\",\n          \"Contact [email\\u00a0protected] +91 98765 43210 Skills \\u2022 Microsoft Office Suite \\u2022 Calendar Management \\u2022 Event Coordination \\u2022 Communication Skills \\u2022 Problem-Solving \\u2022 Time Management Priya Sharma Mumbai, Maharashtra | himalayas.app/@priyasharma Detail-oriented Executive Administrative Assistant with over 5 years of experience in providing comprehensive support to top executives. Proven track record in managing schedules, coordinating meetings, and enhancing office efficiency through effective organizational skills and proactive problem-solving. Professional Experience Tata Consultancy Services Mumbai, Maharashtra Executive Administrative Assistant May 2021 - Present Managed executive calendars, scheduling over 50 meetings weekly while ensuring efficient time management. Organized and coordinated company events, improving participation by 30% through effective communication and planning. Streamlined document management processes, reducing retrieval time by 40% and enhancing operational efficiency. Infosys Bangalore, Karnataka Administrative Assistant Jan 2018 - Apr 2021 Provided administrative support to a team of 10+, handling correspondence and managing travel arrangements. Facilitated onboarding for new employees, ensuring a smooth transition and compliance with company policies. Developed and maintained filing systems, enhancing information accessibility and security. Education University of Mumbai Mumbai, Maharashtra Bachelor of Arts in Business Administration 2014 - 2017 Focused on management principles, communication strategies, and organizational behavior.\",\n          \"Contact [email\\u00a0protected] +1 (555) 987-6543 Skills \\u2022 Financial Modeling \\u2022 Risk Analysis \\u2022 Python \\u2022 SQL \\u2022 Excel Michael Johnson New York, NY | himalayas.app/@michaeljohnson Detail-oriented Junior Derivatives Analyst with over 2 years of experience in financial analysis and derivatives trading. Proven track record in supporting risk management strategies and enhancing trading efficiency through data-driven insights. Professional Experience Goldman Sachs New York, NY Junior Derivatives Analyst Jan 2022 - Present Assisted in the analysis and modeling of derivative products, enhancing decision-making processes for trading strategies. Collaborated with senior analysts to assess market risks, contributing to a 15% reduction in portfolio volatility. Utilized Python and SQL to automate data collection processes, increasing report generation efficiency by 25%. Morgan Stanley New York, NY Financial Analyst Intern Jun 2021 - Dec 2021 Supported the derivatives trading desk in analyzing pricing models and market trends. Developed Excel models to forecast financial performance, leading to actionable insights for trading strategies. Engaged in daily market briefings and contributed to risk assessment reports. Education New York University New York, NY B.S. in Finance 2018 - 2022 Graduated with a focus on financial markets and derivatives. Completed coursework in risk management and quantitative finance.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Processed_Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8221,\n        \"samples\": [\n          \"1 555 9876543 skill team leadership cleaning protocol inventory management safety compliance training development michael thompson toronto ontario himalayasappmichaelthompson dedicated custodial supervisor 6 year experience facility management cleaning operation proven track record leading team maintain cleanliness safety standard diverse environment optimizing cleaning procedure efficiency costeffectiveness professional experience cleansweep service toronto ontario custodial supervisor mar 2021 present supervised team 15 custodial staff ensuring adherence safety protocol high cleaning standard implemented new cleaning schedule improved operational efficiency 30 conducted regular training session equipment usage chemical safety reducing workplace accident 50 sparkleclean inc toronto ontario lead custodian jan 2018 feb 2021 managed daily cleaning operation 200000 sq ft facility ensuring compliance health safety regulation developed maintained inventory tracking system cleaning supply reducing cost 15 collaborated management ensure customer satisfaction resolve cleaningrelated issue promptly metroclean solution toronto ontario custodian may 2016 dec 2017 maintained cleanliness office common area adhering company standard schedule assisted training new staff cleaning procedure safety guideline recognized exceptional service receiving employee month award twice education george brown college toronto ontario diploma facility management 2014 2016 focus operation management health safety regulation cleaning technology\",\n          \"91 98765 43210 skill microsoft office suite calendar management event coordination communication skill problemsolving time management priya sharma mumbai maharashtra himalayasapppriyasharma detailoriented executive administrative assistant 5 year experience providing comprehensive support top executive proven track record managing schedule coordinating meeting enhancing office efficiency effective organizational skill proactive problemsolving professional experience tata consultancy service mumbai maharashtra executive administrative assistant may 2021 present managed executive calendar scheduling 50 meeting weekly ensuring efficient time management organized coordinated company event improving participation 30 effective communication planning streamlined document management process reducing retrieval time 40 enhancing operational efficiency infosys bangalore karnataka administrative assistant jan 2018 apr 2021 provided administrative support team 10 handling correspondence managing travel arrangement facilitated onboarding new employee ensuring smooth transition compliance company policy developed maintained filing system enhancing information accessibility security education university mumbai mumbai maharashtra bachelor art business administration 2014 2017 focused management principle communication strategy organizational behavior\",\n          \"1 555 9876543 skill financial modeling risk analysis python sql excel michael johnson new york ny himalayasappmichaeljohnson detailoriented junior derivative analyst 2 year experience financial analysis derivative trading proven track record supporting risk management strategy enhancing trading efficiency datadriven insight professional experience goldman sachs new york ny junior derivative analyst jan 2022 present assisted analysis modeling derivative product enhancing decisionmaking process trading strategy collaborated senior analyst assess market risk contributing 15 reduction portfolio volatility utilized python sql automate data collection process increasing report generation efficiency 25 morgan stanley new york ny financial analyst intern jun 2021 dec 2021 supported derivative trading desk analyzing pricing model market trend developed excel model forecast financial performance leading actionable insight trading strategy engaged daily market briefing contributed risk assessment report education new york university new york ny b finance 2018 2022 graduated focus financial market derivative completed coursework risk management quantitative finance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Combined_Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8221,\n        \"samples\": [\n          \"janitor skill team leadership cleaning protocol inventory management safety compliance training development michael thompson toronto ontario himalayasappmichaelthompson dedicated custodial supervisor 6 year experience facility management cleaning operation proven track record leading team maintain cleanliness safety standard diverse environment optimizing cleaning procedure efficiency costeffectiveness professional experience cleansweep service toronto ontario custodial supervisor mar 2021 present supervised team 15 custodial staff ensuring adherence safety protocol high cleaning standard implemented new cleaning schedule improved operational efficiency 30 conducted regular training session equipment usage chemical safety reducing workplace accident 50 sparkleclean inc toronto ontario lead custodian jan 2018 feb 2021 managed daily cleaning operation 200000 sq ft facility ensuring compliance health safety regulation developed maintained inventory tracking system cleaning supply reducing cost 15 collaborated management ensure customer satisfaction resolve cleaningrelated issue promptly metroclean solution toronto ontario custodian may 2016 dec 2017 maintained cleanliness office common area adhering company standard schedule assisted training new staff cleaning procedure safety guideline recognized exceptional service receiving employee month award twice education george brown college toronto ontario diploma facility management 2014 2016 focus operation management health safety regulation cleaning technology\",\n          \"executive administrative assistant skill microsoft office suite calendar management event coordination communication skill problemsolving time management priya sharma mumbai maharashtra himalayasapppriyasharma detailoriented executive administrative assistant 5 year experience providing comprehensive support top executive proven track record managing schedule coordinating meeting enhancing office efficiency effective organizational skill proactive problemsolving professional experience tata consultancy service mumbai maharashtra executive administrative assistant may 2021 present managed executive calendar scheduling 50 meeting weekly ensuring efficient time management organized coordinated company event improving participation 30 effective communication planning streamlined document management process reducing retrieval time 40 enhancing operational efficiency infosys bangalore karnataka administrative assistant jan 2018 apr 2021 provided administrative support team 10 handling correspondence managing travel arrangement facilitated onboarding new employee ensuring smooth transition compliance company policy developed maintained filing system enhancing information accessibility security education university mumbai mumbai maharashtra bachelor art business administration 2014 2017 focused management principle communication strategy organizational behavior\",\n          \"derivatives analyst skill financial modeling risk analysis python sql excel michael johnson new york ny himalayasappmichaeljohnson detailoriented junior derivative analyst 2 year experience financial analysis derivative trading proven track record supporting risk management strategy enhancing trading efficiency datadriven insight professional experience goldman sachs new york ny junior derivative analyst jan 2022 present assisted analysis modeling derivative product enhancing decisionmaking process trading strategy collaborated senior analyst assess market risk contributing 15 reduction portfolio volatility utilized python sql automate data collection process increasing report generation efficiency 25 morgan stanley new york ny financial analyst intern jun 2021 dec 2021 supported derivative trading desk analyzing pricing model market trend developed excel model forecast financial performance leading actionable insight trading strategy engaged daily market briefing contributed risk assessment report education new york university new york ny b finance 2018 2022 graduated focus financial market derivative completed coursework risk management quantitative finance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_query_from_document(cv_id, model, tokenizer, df):\n",
        "    \"\"\"\n",
        "    Generate a concise search query representing the content of a document.\n",
        "\n",
        "    Args:\n",
        "        cv_id (str or int): The ID of the document.\n",
        "        model (transformers.PreTrainedModel): The language model for generation.\n",
        "        tokenizer (transformers.PreTrainedTokenizer): The tokenizer associated with the model.\n",
        "        df (pd.DataFrame): A DataFrame containing a 'Combined_Text' column indexed by cv_id.\n",
        "\n",
        "    Returns:\n",
        "        str: A concise search query.\n",
        "    \"\"\"\n",
        "    # Lấy nội dung tài liệu từ DataFrame\n",
        "    try:\n",
        "        contextual_document = df.loc[cv_id, 'Combined_Text']\n",
        "    except KeyError:\n",
        "        raise ValueError(f\"cv_id={cv_id} does not exist in df\")\n",
        "\n",
        "    # Prompt mới để sinh truy vấn\n",
        "    prompt = f\"\"\"\n",
        "You are a helpful assistant. Your task is to generate a short, relevant search query that captures the main idea or purpose of the following document. The query should be concise, focused, and help retrieve this document effectively in a search system. Return only the query, nothing else.\n",
        "\n",
        "Document:\n",
        "<document>\n",
        "{contextual_document}\n",
        "</document>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    # Tokenize và chuẩn bị input\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    input_ids = inputs.to(\"cuda\")\n",
        "    attention_mask = input_ids.ne(tokenizer.pad_token_id).to(\"cuda\")\n",
        "\n",
        "    # Sinh output từ mô hình\n",
        "    outputs = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_new_tokens=32,  # Vì query cần ngắn gọn\n",
        "        do_sample=True,\n",
        "        top_p=0.9,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    # Decode và làm sạch kết quả\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    if \"assistant\" in response:\n",
        "        response = response.split(\"assistant\", 1)[-1].strip()\n",
        "\n",
        "    response = response.strip()\n",
        "\n",
        "    response = response.strip()\n",
        "    delimiter = \"</document>\"\n",
        "    index = response.find(delimiter)\n",
        "\n",
        "    content_after = response[index + len(delimiter):].strip()\n",
        "    return content_after\n"
      ],
      "metadata": {
        "id": "Silfel8C_U-Y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_id = 0  # Example cv_id\n",
        "response = generate_query_from_document(cv_id, model, tokenizer, df)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KQmk5x-ALwk",
        "outputId": "9626de3e-6358-473d-f5de-c848ce4a2c98"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Senior Net Developer with ASP.NET and SQL Server Experience\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "def generate_and_save_queries(df, model, tokenizer, output_csv_path='/content/drive/MyDrive/generated_queries.csv'):\n",
        "    \"\"\"\n",
        "    Generate a query for each document (indexed by cv_id) and save to CSV.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame with 'Combined_Text' and cv_id as index.\n",
        "        model: Language model used for generation.\n",
        "        tokenizer: Tokenizer for the model.\n",
        "        output_csv_path (str): Path to save the results.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The final DataFrame containing generated queries.\n",
        "    \"\"\"\n",
        "    # Use index as cv_id list\n",
        "    cv_ids = df.index.tolist()\n",
        "\n",
        "    # Load previously saved queries if any\n",
        "    if os.path.exists(output_csv_path):\n",
        "        existing_df = pd.read_csv(output_csv_path)\n",
        "        processed_ids = set(existing_df['cv_id'])\n",
        "    else:\n",
        "        processed_ids = set()\n",
        "        pd.DataFrame(columns=['cv_id', 'query']).to_csv(output_csv_path, index=False)\n",
        "\n",
        "    for cv_id in tqdm(cv_ids, desc=\"Generating queries\"):\n",
        "        if cv_id in processed_ids:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            query = generate_query_from_document(cv_id, model, tokenizer, df)\n",
        "            new_row = pd.DataFrame([{\n",
        "                'cv_id': cv_id,\n",
        "                'query': query\n",
        "            }])\n",
        "            new_row.to_csv(output_csv_path, mode='a', header=False, index=False)\n",
        "            processed_ids.add(cv_id)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing cv_id={cv_id}: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"Queries saved to {output_csv_path}\")\n",
        "    return pd.read_csv(output_csv_path)\n"
      ],
      "metadata": {
        "id": "9ot13PfRAWJ2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_csv_path = '/content/drive/MyDrive/generated_queries.csv'\n",
        "query_df = generate_and_save_queries(df, model, tokenizer, output_csv_path)\n",
        "print(query_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOQcSQ_oA4a5",
        "outputId": "76146b82-8a91-48b1-910f-c6545edc3273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Generating queries:  72%|███████▏  | 5916/8221 [2:02:21<51:34,  1.34s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2infev3nBPbH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}